{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0a3464",
   "metadata": {},
   "source": [
    "신경망은 학습 단계에서 최적의 매개변수(가중치와 편향)를 찾아야 하고, 최적이란 손실 함수 값이 최소가 될 때의 매개변수 값이다.  \n",
    "하지만 일반적인 문제의 손실 함수는 매우 복잡하다. 매개변수 공간이 광대하여 어디가 최솟값이 되는지 짐작하기 어렵기 때문.  \n",
    "\n",
    "이런 상황에서 기울기를 이용해 함수의 최솟값을 찾는 것이 바로 경사법이다.\n",
    "> 하지만 기울기가 가리키는 곳이 반드시 함수의 최솟값인지는 보장할 수 없음... 기울기가 0인 장소를 찾아가더라도 복잡하게 이루어진 함수라면 국소적인 최솟값에 빠질 수 있다.\n",
    "\n",
    "경사법은 현 위치에서 기울어진 방향으로 일정 거리만큼 이동한다. 그런 다음 이동한 곳에서도 기울기를 구하고, 또 기울어진 방향으로 나아가기를 반복한다.  \n",
    "이렇게 해서 함수의 값을 점차 줄이는 것이 경사법."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbc956",
   "metadata": {},
   "source": [
    "<img src=\"img/deep_learning_images/e_4.7.png\" height=224 width=224>\n",
    "\n",
    "기호 $\\eta$는 갱신하는 양을 나타내는 것으로, 이를 신경망 학습에서는 학습률-Learning Rate라고 한다.  \n",
    "한 번의 학습으로 매개변수 값을 얼마나 갱신하느냐를 의미.\n",
    "\n",
    "위 식은 1회에 해당하는 갱신을 수식으로 나타낸 것으로 이를 여러 번 반복하면서 서서히 손실 함수의 값을 줄인다.  \n",
    "학습률은 0.01이나 0.001 등 미리 특정한 값으로 정해두어야하며, 값이 너무 크거나 작으면 최적의 장소를 찾아갈 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9458b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a79ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c580c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1] ** 2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197b595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
