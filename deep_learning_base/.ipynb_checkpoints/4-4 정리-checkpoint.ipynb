{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556216e6",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "지금까지 다룬 내용들을 정리해보자.  \n",
    "먼저 신경망에는 가중치와 편향이 있고 이 매개변수들을 훈련 데이터에 적응하도록 조정하는 과정을 학습이라 한다.  \n",
    "1. 전체 학습 데이터 중 일부를 무작위로 선별하여 신경망의 입력으로 사용한다. - batch\n",
    "2. 입력한 데이터에 대한 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 이때 기울기는 손실 함수의 최솟값을 구하는 방향을 제시.\n",
    "3. 매개변수를 기울기 방향으로 아주 조금 갱신한다. - learning rate\n",
    "4. 1 ~ 3을 반복\n",
    "\n",
    "이때 데이터를 무작위로 선정하기 때문에 확률적 경사 하강법(SGD - Stochastic Gradient Descent)라고 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9a09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3257348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe08d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ddadedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1ce622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3551d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c09ab528",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_mnist(pickle_path=\"/data/Datasets/MNIST/mnist.pkl\", normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31311506",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747315d2",
   "metadata": {},
   "source": [
    "배치 크기가 100이므로 매번 60000개의 훈련 데이터에서 임의로 100개의 데이터를 추려낸다.  \n",
    "그리고 배치 데이터들을 대상으로 확률적 경사 하강법을 수행해 매개변수를 갱신한다.\n",
    "\n",
    "경사 하강법으로 갱신하는 횟수를 10000번으로 설정하고 갱신할 때마다 훈련 데이터에 대한 손실함수를 계산하고 리스트에 그 값을 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0808813",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e32fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Iter 1\n",
      "Iter 2\n",
      "Iter 3\n",
      "Iter 4\n",
      "Iter 5\n",
      "Iter 6\n",
      "Iter 7\n",
      "Iter 8\n",
      "Iter 9\n",
      "Iter 10\n",
      "Iter 11\n",
      "Iter 12\n",
      "Iter 13\n",
      "Iter 14\n",
      "Iter 15\n",
      "Iter 16\n",
      "Iter 17\n",
      "Iter 18\n",
      "Iter 19\n",
      "Iter 20\n",
      "Iter 21\n",
      "Iter 22\n",
      "Iter 23\n",
      "Iter 24\n",
      "Iter 25\n",
      "Iter 26\n",
      "Iter 27\n",
      "Iter 28\n",
      "Iter 29\n",
      "Iter 30\n",
      "Iter 31\n",
      "Iter 32\n",
      "Iter 33\n",
      "Iter 34\n",
      "Iter 35\n",
      "Iter 36\n",
      "Iter 37\n",
      "Iter 38\n",
      "Iter 39\n",
      "Iter 40\n",
      "Iter 41\n",
      "Iter 42\n",
      "Iter 43\n",
      "Iter 44\n",
      "Iter 45\n",
      "Iter 46\n",
      "Iter 47\n",
      "Iter 48\n",
      "Iter 49\n",
      "Iter 50\n",
      "Iter 51\n",
      "Iter 52\n",
      "Iter 53\n",
      "Iter 54\n",
      "Iter 55\n",
      "Iter 56\n",
      "Iter 57\n",
      "Iter 58\n",
      "Iter 59\n",
      "Iter 60\n",
      "Iter 61\n",
      "Iter 62\n",
      "Iter 63\n",
      "Iter 64\n",
      "Iter 65\n",
      "Iter 66\n",
      "Iter 67\n",
      "Iter 68\n",
      "Iter 69\n",
      "Iter 70\n",
      "Iter 71\n",
      "Iter 72\n",
      "Iter 73\n",
      "Iter 74\n",
      "Iter 75\n",
      "Iter 76\n",
      "Iter 77\n",
      "Iter 78\n",
      "Iter 79\n",
      "Iter 80\n",
      "Iter 81\n",
      "Iter 82\n",
      "Iter 83\n",
      "Iter 84\n",
      "Iter 85\n",
      "Iter 86\n",
      "Iter 87\n",
      "Iter 88\n",
      "Iter 89\n",
      "Iter 90\n",
      "Iter 91\n",
      "Iter 92\n",
      "Iter 93\n",
      "Iter 94\n",
      "Iter 95\n",
      "Iter 96\n",
      "Iter 97\n",
      "Iter 98\n",
      "Iter 99\n",
      "Iter 100\n",
      "Iter 101\n",
      "Iter 102\n",
      "Iter 103\n",
      "Iter 104\n",
      "Iter 105\n",
      "Iter 106\n",
      "Iter 107\n",
      "Iter 108\n",
      "Iter 109\n",
      "Iter 110\n",
      "Iter 111\n",
      "Iter 112\n",
      "Iter 113\n",
      "Iter 114\n",
      "Iter 115\n",
      "Iter 116\n",
      "Iter 117\n",
      "Iter 118\n",
      "Iter 119\n",
      "Iter 120\n",
      "Iter 121\n",
      "Iter 122\n",
      "Iter 123\n",
      "Iter 124\n",
      "Iter 125\n",
      "Iter 126\n",
      "Iter 127\n",
      "Iter 128\n",
      "Iter 129\n",
      "Iter 130\n",
      "Iter 131\n",
      "Iter 132\n",
      "Iter 133\n",
      "Iter 134\n",
      "Iter 135\n",
      "Iter 136\n",
      "Iter 137\n",
      "Iter 138\n",
      "Iter 139\n",
      "Iter 140\n",
      "Iter 141\n",
      "Iter 142\n",
      "Iter 143\n",
      "Iter 144\n",
      "Iter 145\n",
      "Iter 146\n",
      "Iter 147\n",
      "Iter 148\n",
      "Iter 149\n",
      "Iter 150\n",
      "Iter 151\n",
      "Iter 152\n",
      "Iter 153\n",
      "Iter 154\n",
      "Iter 155\n",
      "Iter 156\n",
      "Iter 157\n",
      "Iter 158\n",
      "Iter 159\n",
      "Iter 160\n",
      "Iter 161\n",
      "Iter 162\n",
      "Iter 163\n",
      "Iter 164\n",
      "Iter 165\n",
      "Iter 166\n",
      "Iter 167\n",
      "Iter 168\n",
      "Iter 169\n",
      "Iter 170\n",
      "Iter 171\n",
      "Iter 172\n",
      "Iter 173\n",
      "Iter 174\n",
      "Iter 175\n",
      "Iter 176\n",
      "Iter 177\n",
      "Iter 178\n",
      "Iter 179\n",
      "Iter 180\n",
      "Iter 181\n",
      "Iter 182\n",
      "Iter 183\n",
      "Iter 184\n",
      "Iter 185\n",
      "Iter 186\n",
      "Iter 187\n",
      "Iter 188\n",
      "Iter 189\n",
      "Iter 190\n",
      "Iter 191\n",
      "Iter 192\n",
      "Iter 193\n",
      "Iter 194\n",
      "Iter 195\n",
      "Iter 196\n",
      "Iter 197\n",
      "Iter 198\n",
      "Iter 199\n",
      "Iter 200\n",
      "Iter 201\n",
      "Iter 202\n",
      "Iter 203\n",
      "Iter 204\n",
      "Iter 205\n",
      "Iter 206\n",
      "Iter 207\n",
      "Iter 208\n",
      "Iter 209\n",
      "Iter 210\n",
      "Iter 211\n",
      "Iter 212\n",
      "Iter 213\n",
      "Iter 214\n",
      "Iter 215\n",
      "Iter 216\n",
      "Iter 217\n",
      "Iter 218\n",
      "Iter 219\n",
      "Iter 220\n",
      "Iter 221\n",
      "Iter 222\n",
      "Iter 223\n",
      "Iter 224\n",
      "Iter 225\n",
      "Iter 226\n",
      "Iter 227\n",
      "Iter 228\n",
      "Iter 229\n",
      "Iter 230\n",
      "Iter 231\n",
      "Iter 232\n",
      "Iter 233\n",
      "Iter 234\n",
      "Iter 235\n",
      "Iter 236\n",
      "Iter 237\n",
      "Iter 238\n",
      "Iter 239\n",
      "Iter 240\n",
      "Iter 241\n",
      "Iter 242\n",
      "Iter 243\n",
      "Iter 244\n",
      "Iter 245\n",
      "Iter 246\n",
      "Iter 247\n",
      "Iter 248\n",
      "Iter 249\n",
      "Iter 250\n",
      "Iter 251\n",
      "Iter 252\n",
      "Iter 253\n",
      "Iter 254\n",
      "Iter 255\n",
      "Iter 256\n",
      "Iter 257\n",
      "Iter 258\n",
      "Iter 259\n",
      "Iter 260\n",
      "Iter 261\n",
      "Iter 262\n",
      "Iter 263\n",
      "Iter 264\n",
      "Iter 265\n",
      "Iter 266\n",
      "Iter 267\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_337970/2383760308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# 기울기 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_337970/1361659197.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_337970/451746592.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x-h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_337970/1361659197.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_337970/1361659197.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_337970/1361659197.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    print(f\"Iter {i}\")\n",
    "    batch_set = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_set]\n",
    "    y_batch = y_train[batch_set]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, y_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, y_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f29764",
   "metadata": {},
   "source": [
    "학습 데이터의 배치 데이터에 대한 손실 함수값이 감소. 이것이 신경망이 잘 학습하고 있다는 지표이지만, 실제 현실 서비스에 적용할 범용성을 갖추고 있는지는 아직 모른다.\n",
    "\n",
    "신경망 학습에서는 학습 데이터외의 데이터를 올바르게 인식하는지 확인해야 하는데 이를 다른 말로 오버피팅을 일으키지 않았는지 확인하는 것이다.  \n",
    "오버피팅이 발생하면 학습 데이터에 포함된 이미지만 제대로 구분하고, 그렇지 않은 데이터는 식별하지 못함.  \n",
    "따라서 테스트 데이터 대상으로 정확도를 기록해보자.\n",
    "\n",
    "여기서는 1 epoch별로 테스트 데이터에 대한 정확도를 기록할 것이다.\n",
    "> 1 epoch은 학습 데이터를 모두 소진했을 때의 횟수에 해당. 10000개의 학습 데이터를 100개의 배치로 학습한다면 SGD로 100회 반복하면 모든 학습 데이터를 소진한 것이 된다. 따라서 100회 반복 = 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_sizeeeezezezezeze / batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ac04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choicececececece(train_size, batch_size)\n",
    "    x_batch, y_batch = x_train[batch_mask], y_train[batch_mask]\n",
    "    \n",
    "    grad = network.numerical_gradient(x_batch, y_batch)\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, y_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, y_train)\n",
    "        test_acc = network.accuracy(x_test, y_test)\n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "        print(f\"train acc, test acc | {train_acc}, {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d84e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
